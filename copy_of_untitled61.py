# -*- coding: utf-8 -*-
"""Copy of Untitled61.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12scEKD2gJtVrjciSQr2WHRXyt412Gsny
"""

import pandas as pd
import numpy as np

# Load the dataset
data = pd.read_csv("/content/ratings_Electronics (1).csv", header=None)

# Rename columns for easier reference
data.columns = ["ID", "Product_ID", "Feedback", "Timestamp"]

# Display the first few rows and summary information
print("First few rows of the dataset:")
print(data.head())

print("\nSummary information:")
print(data.info())

# Check for unique entries in each column
print("\nUnique counts in each column:")
print(data.nunique())

# Step 2: Data Cleaning

# 1. Handling Missing Values

print("\nMissing values in each column:")
print(data.isnull().sum())
duplicates = data.duplicated(subset=["ID", "Feedback"])
print(f"\nNumber of duplicate entries: {duplicates.sum()}")
data = data.drop_duplicates(subset=["ID", "Feedback"])
data["Feedback"] = data["Feedback"].astype(float)

# This step ensures that Product_IDs containing letters or numbers retain their format
data["Product_ID"] = data["Product_ID"].astype(str)

# Step 3: Converting Feedback to Integer Values

data["Feedback"] = data["Feedback"].round().astype(int)

print("\nData after cleaning and conversion:")
print(data.head())

# Step 4: Saving the Cleaned Dataset

data.to_csv("cleaned_dataset.csv", index=False)
print("\nCleaned dataset saved as 'cleaned_dataset.csv'")

import pandas as pd
import numpy as np

# Load the dataset
data = pd.read_csv("/content/ratings_Electronics (1).csv", header=None)

# Rename columns for easier reference
data.columns = ["ID", "Product_ID", "Feedback", "Timestamp"]

# Display the first few rows and summary information
print("First few rows of the dataset:")
print(data.head())

print("\nSummary information:")
print(data.info())

# Check for unique entries in each column
print("\nUnique counts in each column:")
print(data.nunique())

# Step 2: Data Cleaning
print("\nMissing values in each column:")
print(data.isnull().sum())
duplicates = data.duplicated(subset=["ID", "Feedback"])
print(f"\nNumber of duplicate entries: {duplicates.sum()}")
data = data.drop_duplicates(subset=["ID", "Feedback"])
data["Feedback"] = data["Feedback"].astype(float)

# This step ensures that Product_IDs containing letters or numbers retain their format
data["Product_ID"] = data["Product_ID"].astype(str)

# Step 3: Converting Feedback to Integer Values
data["Feedback"] = data["Feedback"].round().astype(int)

print("\nData after cleaning and conversion:")
print(data.head())

# Step 4: Select 5 unique users and 5 unique products
selected_users = data["ID"].unique()[:5]
selected_products = data["Product_ID"].unique()[:5]

# Filter the dataset
filtered_data = data[data["ID"].isin(selected_users) & data["Product_ID"].isin(selected_products)]

# Step 5: Create the user-item matrix
user_item_matrix = filtered_data.pivot_table(index="ID", columns="Product_ID", values="Feedback", fill_value=0)

# Display the matrix
print("\nUser-Item Matrix:")
print(user_item_matrix)

# Step 6: Save the cleaned user-item matrix as a CSV (optional)
user_item_matrix.to_csv("user_item_matrix.csv", index=True)
print("\nUser-item matrix saved as 'user_item_matrix.csv'")

import pandas as pd

# Load the user-item matrix dataset (assuming you already have it as a DataFrame)
df = pd.read_csv("/content/user_item_matrix.csv", index_col=0)

# Display the matrix to verify data
print("User-Item Matrix:")
print(df)

# Compute the average rating (ignoring zeros as they represent no feedback)
average_rating_overall = df.replace(0, pd.NA).mean().mean()
print("\nOverall average rating (ignoring zeros):", average_rating_overall)

# Compute the average rating per user (ignoring zeros)
average_rating_per_user = df.replace(0, pd.NA).mean(axis=1)
print("\nAverage rating per user (ignoring zeros):")
print(average_rating_per_user)

# Compute the average rating per product (ignoring zeros)
average_rating_per_product = df.replace(0, pd.NA).mean(axis=0)
print("\nAverage rating per product (ignoring zeros):")
print(average_rating_per_product)

# Include the results in your report under the "Assignment Results" section.

import pandas as pd
import numpy as np
from scipy.spatial.distance import cosine
from scipy.stats import pearsonr

# Create the DataFrame for your 5x5 matrix
data = {
    "Product/User ID": ["A1GIOU4ZRJA8WN", "A2CX7LUOHB2NDG", "A2NWSAGRHCP8N5", "A2WNBOD3WDNKKT", "AKM1MP6P00YPR"],
    "1327940": [0, 0, 0, 0, 5],
    "321732944": [0, 5, 0, 0, 0],
    "439886341": [0, 0, 0, 0, 0],
    "B001E4KFG0": [2, 3, 4, 0, 1],
    "B00004Z5M1": [0, 1, 0, 5, 0]
}

df = pd.DataFrame(data).set_index("Product/User ID")
print("Original Matrix:")
print(df)

#Step 1: Compute Cosine Similarity (User-Based)
from sklearn.metrics.pairwise import cosine_similarity

# Calculate cosine similarity for users (rows)
cosine_sim_users = cosine_similarity(df)
cosine_sim_users_df = pd.DataFrame(cosine_sim_users, index=df.index, columns=df.index)

print("\nCosine Similarity (User-Based):")
print(cosine_sim_users_df)

#Step 2: Compute Pearson Correlation (User-Based)
# Calculate Pearson correlation for users
pearson_corr_users = df.T.corr(method='pearson')
print("\nPearson Correlation (User-Based):")
print(pearson_corr_users)

#Step 3: Compute Cosine Similarity (Item-Based)
# Calculate cosine similarity for items (columns)
cosine_sim_items = cosine_similarity(df.T)
cosine_sim_items_df = pd.DataFrame(cosine_sim_items, index=df.columns, columns=df.columns)

print("\nCosine Similarity (Item-Based):")
print(cosine_sim_items_df)

#Step 4: Compute Pearson Correlation (Item-Based)
# Calculate Pearson correlation for items
pearson_corr_items = df.corr(method='pearson')
print("\nPearson Correlation (Item-Based):")
print(pearson_corr_items)

import numpy as np
from scipy.spatial.distance import cosine
from scipy.stats import pearsonr

# Example 5x5 user-item matrix
ratings_matrix = np.array([
    [0, 0, 0, 2, 0],
    [0, 5, 0, 3, 1],
    [0, 0, 0, 4, 0],
    [0, 0, 3, 0, 5],
    [5, 0, 0, 1, 0]
])

# Calculate mean ratings for each user
user_means = np.mean(np.where(ratings_matrix > 0, ratings_matrix, np.nan), axis=1)

# Fill NaN with zeros for calculations
filled_matrix = np.nan_to_num(ratings_matrix)

# Function to calculate cosine similarity
def cosine_similarity(matrix):
    similarity = np.zeros((matrix.shape[0], matrix.shape[0]))
    for i in range(matrix.shape[0]):
        for j in range(matrix.shape[0]):
            if i != j:
                similarity[i, j] = 1 - cosine(matrix[i], matrix[j])
    return similarity

# Function to calculate Pearson correlation
def pearson_similarity(matrix):
    similarity = np.zeros((matrix.shape[0], matrix.shape[0]))
    for i in range(matrix.shape[0]):
        for j in range(matrix.shape[0]):
            if i != j:
                corr, _ = pearsonr(matrix[i], matrix[j])
                similarity[i, j] = corr if not np.isnan(corr) else 0
    return similarity

# Compute cosine similarity and Pearson correlation for users
user_cosine_sim = cosine_similarity(filled_matrix)
user_pearson_sim = pearson_similarity(filled_matrix)

# Rating prediction using similarity
def predict_rating(user_id, item_id, similarity_matrix, k=2):
    similar_users = [(other, similarity_matrix[user_id, other]) for other in range(len(similarity_matrix))
                     if other != user_id and ratings_matrix[other, item_id] > 0]

    # Sort similar users by similarity
    similar_users = sorted(similar_users, key=lambda x: x[1], reverse=True)[:k]

    numerator = sum(similarity * (ratings_matrix[other, item_id] - user_means[other])
                    for other, similarity in similar_users)
    denominator = sum(abs(similarity) for _, similarity in similar_users)

    if denominator == 0:
        return user_means[user_id]

    return user_means[user_id] + numerator / denominator

# Generate predictions for each user-item pair (5x5 matrix)
predictions_cosine = np.zeros_like(ratings_matrix, dtype=float)
predictions_pearson = np.zeros_like(ratings_matrix, dtype=float)

for user_id in range(ratings_matrix.shape[0]):
    for item_id in range(ratings_matrix.shape[1]):
        if ratings_matrix[user_id, item_id] == 0:  # Predict only for unrated items
            predictions_cosine[user_id, item_id] = predict_rating(user_id, item_id, user_cosine_sim)
            predictions_pearson[user_id, item_id] = predict_rating(user_id, item_id, user_pearson_sim)

# Function to get top-N recommendations
def get_top_n_recommendations(predictions, N=2):
    recommendations = {}
    for user_id in range(predictions.shape[0]):
        user_predictions = predictions[user_id]
        top_items = np.argsort(user_predictions)[-N:][::-1]
        recommendations[user_id] = top_items
    return recommendations

# Get top-N recommendations for cosine and Pearson predictions
top_n_cosine = get_top_n_recommendations(predictions_cosine, N=2)
top_n_pearson = get_top_n_recommendations(predictions_pearson, N=2)

# Display the results
print("Cosine Similarity Matrix:\n", user_cosine_sim)
print("\nPearson Similarity Matrix:\n", user_pearson_sim)
print("\nPredicted Ratings using Cosine Similarity:\n", predictions_cosine)
print("\nPredicted Ratings using Pearson Correlation:\n", predictions_pearson)
print("\nTop-N Recommendations using Cosine Similarity:", top_n_cosine)
print("\nTop-N Recommendations using Pearson Correlation:", top_n_pearson)